{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 8. Central Limit Theorem\n", "\n", "**Goal:** Demonstrate universality of the Gaussian.\n", "\n", "$$Z_n = \\frac{\\sum X_i - n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0,1)$$"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)\nN_s = 100000\nsizes = [1, 2, 5, 10, 30, 100]\ndists = [\n    ('Bernoulli(0.3)', lambda s: np.random.binomial(1,0.3,s), 0.3, 0.21),\n    ('Exponential(1)', lambda s: np.random.exponential(1,s), 1.0, 1.0),\n    ('Uniform(0,1)', lambda s: np.random.uniform(0,1,s), 0.5, 1/12),\n    ('Poisson(2)', lambda s: np.random.poisson(2,s).astype(float), 2.0, 2.0),\n]\nfig, axes = plt.subplots(len(dists), len(sizes), figsize=(20, 3.5*len(dists)))\nxg = np.linspace(-4,4,200)\nfor row,(name,sampler,mu,var) in enumerate(dists):\n    sig = np.sqrt(var)\n    for col,n in enumerate(sizes):\n        ax = axes[row][col]\n        Z = (np.sum(sampler((N_s,n)),axis=1) - n*mu)/(sig*np.sqrt(n))\n        ax.hist(Z, bins=60, density=True, alpha=0.6, color='steelblue')\n        ax.plot(xg, stats.norm.pdf(xg), 'r-', linewidth=2)\n        ax.set_xlim(-4,4); ax.set_ylim(0,0.55); ax.set_yticks([])\n        if row==0: ax.set_title(f'n={n}')\n        if col==0: ax.set_ylabel(name)\nplt.suptitle('CLT: All -> N(0,1)', fontsize=15, y=1.02)\nplt.tight_layout()\nplt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Convergence Rate (Berry-Esseen)"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ks_normal(s):\n    s = np.sort(s)\n    return np.max(np.abs(np.arange(1,len(s)+1)/len(s) - stats.norm.cdf(s)))\n\nnp.random.seed(42)\nss = np.unique(np.logspace(0.5,4,30).astype(int))\nfig, ax = plt.subplots(figsize=(10,6))\nfor name,sampler,mu,var in dists:\n    sig = np.sqrt(var)\n    ks = [ks_normal((np.sum(sampler((50000,n)),axis=1)-n*mu)/(sig*np.sqrt(n))) for n in ss]\n    ax.plot(ss, ks, 'o-', markersize=4, label=name)\nax.plot(ss, 0.5/np.sqrt(ss), 'k--', alpha=0.5, label='O(1/sqrt(n))')\nax.set_xscale('log'); ax.set_yscale('log')\nax.set_xlabel('n'); ax.set_ylabel('KS distance')\nax.set_title('Rate of CLT Convergence'); ax.legend(); ax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## CLT Fails: Cauchy"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)\nfig, axes = plt.subplots(1, 3, figsize=(16,5))\nfor col,n in enumerate([10,100,1000]):\n    ax = axes[col]\n    Z = np.mean(np.random.standard_cauchy((50000,n)), axis=1)\n    Zc = Z[(Z>-20)&(Z<20)]\n    ax.hist(Zc, bins=100, density=True, alpha=0.6, color='orange')\n    xg = np.linspace(-20,20,500)\n    ax.plot(xg, stats.norm.pdf(xg), 'r-', label='N(0,1)')\n    ax.plot(xg, stats.cauchy.pdf(xg), 'b-', label='Cauchy')\n    ax.set_title(f'n={n}: still Cauchy'); ax.set_xlim(-20,20); ax.legend(fontsize=9)\nplt.suptitle('CLT Fails: Cauchy (infinite variance)', fontsize=13, y=1.02)\nplt.tight_layout()\nplt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Key Takeaways\n", "\n", "1. **Universality:** works for any finite-variance distribution.\n", "2. **Rate:** $O(1/\\sqrt{n})$ (Berry-Esseen).\n", "3. **Finite variance essential:** Cauchy sums stay Cauchy.\n", "4. Explains ubiquity of the normal distribution."]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.0"}},
 "nbformat": 4, "nbformat_minor": 4
}