{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Brownian Motion: Properties\n",
    "\n",
    "**Goal:** Numerically verify the remarkable analytic properties of Brownian motion.\n",
    "\n",
    "Brownian motion is the canonical example of a process that is:\n",
    "- **Continuous** everywhere (a.s.)\n",
    "- **Nowhere differentiable** (a.s.)\n",
    "- Has **quadratic variation** $[B]_t = t$\n",
    "- Is **self-similar:** $B(ct) \\stackrel{d}{=} \\sqrt{c}\\, B(t)$\n",
    "\n",
    "These properties are deeply tied to the measure-theoretic structure of Wiener measure on path space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuity and Nowhere Differentiability\n",
    "\n",
    "Although $B_t$ is continuous, the finite-difference approximation to its derivative:\n",
    "$$\\frac{B(t+h) - B(t)}{h}$$\n",
    "does **not** converge as $h \\to 0$. In fact, $|B(t+h) - B(t)| \\sim \\sqrt{h}$, so the ratio blows up as $h^{-1/2}$.\n",
    "\n",
    "This is a consequence of the Holder continuity exponent being $1/2 - \\varepsilon$ for any $\\varepsilon > 0$, but never $1/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate a fine Brownian motion path\n",
    "n_fine = 100000\n",
    "T = 1.0\n",
    "dt_fine = T / n_fine\n",
    "t_fine = np.linspace(0, T, n_fine + 1)\n",
    "B = np.concatenate([[0], np.cumsum(np.sqrt(dt_fine) * np.random.randn(n_fine))])\n",
    "\n",
    "# Compute finite-difference \"derivatives\" at different scales\n",
    "h_values = [1000, 200, 50, 10]  # in units of dt_fine\n",
    "h_labels = [f'h = {h * dt_fine:.4f}' for h in h_values]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (h_steps, label) in enumerate(zip(h_values, h_labels)):\n",
    "    ax = axes[idx]\n",
    "    h = h_steps * dt_fine\n",
    "    # Finite difference at each point\n",
    "    deriv = (B[h_steps:] - B[:-h_steps]) / h\n",
    "    t_deriv = t_fine[:-h_steps]\n",
    "    \n",
    "    ax.plot(t_deriv[::max(1, h_steps//2)], deriv[::max(1, h_steps//2)],\n",
    "            linewidth=0.4, color='steelblue')\n",
    "    ax.set_title(f'{label}\\nmax|deriv| = {np.max(np.abs(deriv)):.1f}', fontsize=11)\n",
    "    ax.set_xlabel('t'); ax.set_ylabel('$(B(t+h) - B(t))/h$')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Finite Differences Blow Up: Nowhere Differentiability', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quantitative: max of |derivative| vs h\n",
    "h_range = np.logspace(0, 3.5, 30).astype(int)\n",
    "h_range = np.unique(np.clip(h_range, 1, n_fine // 2))\n",
    "max_derivs = []\n",
    "for h_steps in h_range:\n",
    "    h = h_steps * dt_fine\n",
    "    deriv = (B[h_steps:] - B[:-h_steps]) / h\n",
    "    max_derivs.append(np.max(np.abs(deriv)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "h_actual = h_range * dt_fine\n",
    "ax.loglog(h_actual, max_derivs, 'o-', color='steelblue', markersize=4, label='max $|\\\\Delta B/h|$')\n",
    "# Reference line: h^{-1/2}\n",
    "c_ref = max_derivs[len(max_derivs)//2] * h_actual[len(h_actual)//2]**0.5\n",
    "ax.loglog(h_actual, c_ref * h_actual**(-0.5), 'r--', linewidth=2, label='$h^{-1/2}$ reference')\n",
    "ax.set_xlabel('h'); ax.set_ylabel('max $|\\\\Delta B / h|$')\n",
    "ax.set_title('Derivative blows up as $h^{-1/2}$', fontsize=12)\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Variation: $[B]_t = t$\n",
    "\n",
    "For a partition $\\Pi = \\{0 = t_0 < t_1 < \\cdots < t_n = t\\}$ with mesh $|\\Pi| \\to 0$:\n",
    "$$[B]_t = \\lim_{|\\Pi| \\to 0} \\sum_{k=0}^{n-1} (B_{t_{k+1}} - B_{t_k})^2 = t \\quad \\text{(in } L^2 \\text{ and a.s.)}$$\n",
    "\n",
    "This is fundamentally different from smooth functions, whose quadratic variation is always 0.\n",
    "It is the key reason why stochastic calculus differs from ordinary calculus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2024)\n",
    "\n",
    "T = 1.0\n",
    "n_fine = 50000\n",
    "dt_fine = T / n_fine\n",
    "t_fine = np.linspace(0, T, n_fine + 1)\n",
    "B = np.concatenate([[0], np.cumsum(np.sqrt(dt_fine) * np.random.randn(n_fine))])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: QV as function of t for different partition sizes\n",
    "n_partitions = [50, 200, 1000, 5000]\n",
    "for n_part in n_partitions:\n",
    "    step = n_fine // n_part\n",
    "    indices = np.arange(0, n_fine + 1, step)\n",
    "    B_part = B[indices]\n",
    "    t_part = t_fine[indices]\n",
    "    increments_sq = np.diff(B_part)**2\n",
    "    qv_cumulative = np.concatenate([[0], np.cumsum(increments_sq)])\n",
    "    ax1.plot(t_part, qv_cumulative, linewidth=1.2, label=f'n = {n_part}')\n",
    "\n",
    "ax1.plot([0, T], [0, T], 'k--', linewidth=2, label='$[B]_t = t$')\n",
    "ax1.set_xlabel('t'); ax1.set_ylabel('$\\\\sum (\\\\Delta B)^2$')\n",
    "ax1.set_title('Cumulative Quadratic Variation', fontsize=12)\n",
    "ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: total QV at t=1 for many partition sizes\n",
    "n_range = np.logspace(1, 4, 40).astype(int)\n",
    "n_range = np.unique(n_range)\n",
    "qv_totals = []\n",
    "for n_part in n_range:\n",
    "    step = max(1, n_fine // n_part)\n",
    "    indices = np.arange(0, n_fine + 1, step)\n",
    "    increments_sq = np.diff(B[indices])**2\n",
    "    qv_totals.append(np.sum(increments_sq))\n",
    "\n",
    "ax2.semilogx(n_range, qv_totals, 'o-', color='steelblue', markersize=3)\n",
    "ax2.axhline(y=T, color='red', linestyle='--', linewidth=2, label='$[B]_1 = 1$')\n",
    "ax2.set_xlabel('Number of partition points')\n",
    "ax2.set_ylabel('$\\\\sum (\\\\Delta B)^2$')\n",
    "ax2.set_title('$[B]_1 \\\\to 1$ as mesh $\\\\to 0$', fontsize=12)\n",
    "ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0.5, 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare with first variation (total variation)\n",
    "print('First variation (total variation) comparison:')\n",
    "for n_part in [100, 500, 2000, 10000]:\n",
    "    step = max(1, n_fine // n_part)\n",
    "    indices = np.arange(0, n_fine + 1, step)\n",
    "    fv = np.sum(np.abs(np.diff(B[indices])))\n",
    "    qv = np.sum(np.diff(B[indices])**2)\n",
    "    print(f'  n={n_part:5d}:  first variation = {fv:.3f},  quadratic variation = {qv:.4f}')\n",
    "print('\\nFirst variation -> infinity, quadratic variation -> 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Similarity\n",
    "\n",
    "Brownian motion has a scaling property: for any $c > 0$,\n",
    "$$\\{B(ct)\\}_{t \\geq 0} \\stackrel{d}{=} \\{\\sqrt{c}\\, B(t)\\}_{t \\geq 0}$$\n",
    "\n",
    "This means zooming into a Brownian path (rescaling time by $c$ and space by $\\sqrt{c}$) yields a statistically identical process. We verify this by comparing distributions at fixed times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)\n",
    "\n",
    "n_paths = 10000\n",
    "n_steps = 2000\n",
    "T = 4.0\n",
    "dt = T / n_steps\n",
    "t_grid = np.linspace(0, T, n_steps + 1)\n",
    "\n",
    "inc = np.sqrt(dt) * np.random.randn(n_paths, n_steps)\n",
    "B = np.zeros((n_paths, n_steps + 1))\n",
    "B[:, 1:] = np.cumsum(inc, axis=1)\n",
    "\n",
    "c_values = [0.25, 1.0, 4.0]\n",
    "t_eval = 1.0  # evaluate at t=1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: visual comparison of B(ct) and sqrt(c)*B(t)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "x_range = np.linspace(-5, 5, 200)\n",
    "\n",
    "for c, color in zip(c_values, colors):\n",
    "    ct_idx = min(int(c * t_eval / dt), n_steps)\n",
    "    B_ct = B[:, ct_idx]  # B(c*t)\n",
    "    scaled_B = np.sqrt(c) * B[:, int(t_eval / dt)]  # sqrt(c) * B(t)\n",
    "    \n",
    "    ax1.hist(B_ct, bins=50, density=True, alpha=0.4, color=color,\n",
    "             label=f'B({c}), var={np.var(B_ct):.2f}')\n",
    "    ax1.plot(x_range, stats.norm.pdf(x_range, 0, np.sqrt(c * t_eval)),\n",
    "             color=color, linewidth=2)\n",
    "\n",
    "ax1.set_title(f'$B(c \\\\cdot {t_eval})$ for different $c$', fontsize=12)\n",
    "ax1.set_xlabel('Value'); ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: QQ plot comparing B(ct) vs sqrt(c)*B(t)\n",
    "c_test = 4.0\n",
    "ct_idx = min(int(c_test * t_eval / dt), n_steps)\n",
    "t_idx = int(t_eval / dt)\n",
    "B_ct = np.sort(B[:, ct_idx])\n",
    "scaled_B = np.sort(np.sqrt(c_test) * B[:, t_idx])\n",
    "\n",
    "ax2.scatter(scaled_B, B_ct, s=1, alpha=0.3, color='steelblue')\n",
    "lim = max(np.abs(B_ct).max(), np.abs(scaled_B).max())\n",
    "ax2.plot([-lim, lim], [-lim, lim], 'r--', linewidth=2, label='y = x')\n",
    "ax2.set_xlabel(f'$\\\\sqrt{{{c_test:.0f}}} \\\\cdot B({t_eval})$')\n",
    "ax2.set_ylabel(f'$B({c_test * t_eval:.0f})$')\n",
    "ax2.set_title(f'QQ: $B({c_test:.0f}) \\\\stackrel{{d}}{{=}} \\\\sqrt{{{c_test:.0f}}} \\\\cdot B({t_eval})$', fontsize=12)\n",
    "ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "# KS test\n",
    "ks_stat, ks_p = stats.ks_2samp(B[:, ct_idx], np.sqrt(c_test) * B[:, t_idx])\n",
    "ax2.text(0.05, 0.95, f'KS p-value = {ks_p:.3f}', transform=ax2.transAxes,\n",
    "         fontsize=10, va='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Principle and Hitting Times\n",
    "\n",
    "The **reflection principle** states: for a level $a > 0$,\n",
    "$$P(\\max_{0 \\leq s \\leq t} B_s \\geq a) = 2\\, P(B_t \\geq a) = 2\\,[1 - \\Phi(a/\\sqrt{t})]$$\n",
    "\n",
    "The **first hitting time** $\\tau_a = \\inf\\{t \\geq 0 : B_t = a\\}$ has the Levy distribution:\n",
    "$$f_{\\tau_a}(t) = \\frac{|a|}{\\sqrt{2\\pi t^3}}\\, \\exp\\!\\left(-\\frac{a^2}{2t}\\right), \\quad t > 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2024)\n",
    "\n",
    "n_paths = 20000\n",
    "n_steps = 10000\n",
    "T = 5.0\n",
    "dt = T / n_steps\n",
    "t_grid = np.linspace(0, T, n_steps + 1)\n",
    "\n",
    "inc = np.sqrt(dt) * np.random.randn(n_paths, n_steps)\n",
    "B = np.zeros((n_paths, n_steps + 1))\n",
    "B[:, 1:] = np.cumsum(inc, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Left: reflection principle verification\n",
    "ax = axes[0]\n",
    "a_values = np.linspace(0.1, 3.0, 50)\n",
    "t_check = 2.0\n",
    "t_idx = int(t_check / dt)\n",
    "running_max = np.max(B[:, :t_idx+1], axis=1)\n",
    "\n",
    "prob_max_empirical = [np.mean(running_max >= a) for a in a_values]\n",
    "prob_max_theory = [2 * (1 - stats.norm.cdf(a / np.sqrt(t_check))) for a in a_values]\n",
    "\n",
    "ax.plot(a_values, prob_max_empirical, 'o', markersize=3, color='steelblue', label='Simulated')\n",
    "ax.plot(a_values, prob_max_theory, 'r-', linewidth=2, label='$2[1-\\\\Phi(a/\\\\sqrt{t})]$')\n",
    "ax.set_xlabel('Level $a$'); ax.set_ylabel('$P(\\\\max_{s \\\\leq t} B_s \\\\geq a)$')\n",
    "ax.set_title(f'Reflection Principle (t = {t_check})', fontsize=12)\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Middle: hitting time distribution\n",
    "ax = axes[1]\n",
    "a = 1.0\n",
    "hit_times = []\n",
    "for i in range(n_paths):\n",
    "    crossings = np.where(B[i, :] >= a)[0]\n",
    "    if len(crossings) > 0:\n",
    "        hit_times.append(crossings[0] * dt)\n",
    "\n",
    "hit_times = np.array(hit_times)\n",
    "t_range = np.linspace(0.01, T, 500)\n",
    "levy_pdf = (a / np.sqrt(2 * np.pi * t_range**3)) * np.exp(-a**2 / (2 * t_range))\n",
    "\n",
    "ax.hist(hit_times, bins=60, density=True, color='steelblue', alpha=0.7,\n",
    "        edgecolor='navy', linewidth=0.3, range=(0, T))\n",
    "ax.plot(t_range, levy_pdf, 'r-', linewidth=2, label='Levy density')\n",
    "ax.set_xlabel('$\\\\tau_a$'); ax.set_ylabel('Density')\n",
    "ax.set_title(f'Hitting Time $\\\\tau_{{{a}}}$\\n(hit in {len(hit_times)}/{n_paths} paths)', fontsize=12)\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, T)\n",
    "\n",
    "# Right: reflected paths\n",
    "ax = axes[2]\n",
    "a_reflect = 1.5\n",
    "n_show = 8\n",
    "for i in range(n_show):\n",
    "    path = B[i].copy()\n",
    "    cross_idx = np.where(path >= a_reflect)[0]\n",
    "    if len(cross_idx) > 0:\n",
    "        first_cross = cross_idx[0]\n",
    "        # Original path\n",
    "        ax.plot(t_grid[:first_cross+1], path[:first_cross+1],\n",
    "                color=f'C{i}', linewidth=0.8, alpha=0.7)\n",
    "        ax.plot(t_grid[first_cross:], path[first_cross:],\n",
    "                color=f'C{i}', linewidth=0.8, alpha=0.3)\n",
    "        # Reflected path\n",
    "        reflected = 2 * a_reflect - path[first_cross:]\n",
    "        ax.plot(t_grid[first_cross:], reflected,\n",
    "                color=f'C{i}', linewidth=0.8, alpha=0.7, linestyle='--')\n",
    "    else:\n",
    "        ax.plot(t_grid, path, color=f'C{i}', linewidth=0.8, alpha=0.7)\n",
    "\n",
    "ax.axhline(y=a_reflect, color='red', linestyle='-', linewidth=2, alpha=0.5, label=f'$a = {a_reflect}$')\n",
    "ax.set_xlabel('t'); ax.set_ylabel('$B_t$')\n",
    "ax.set_title('Reflected Paths (dashed = reflected)', fontsize=12)\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Nowhere differentiable:** finite-difference derivatives diverge as $h^{-1/2}$ -- Brownian paths are Holder-$\\alpha$ only for $\\alpha < 1/2$.\n",
    "2. **Quadratic variation $[B]_t = t$:** this is the fundamental reason stochastic calculus differs from ordinary calculus. Smooth functions have zero quadratic variation; Brownian motion does not.\n",
    "3. **First variation is infinite:** $\\sum |\\Delta B| \\to \\infty$ as the mesh refines, confirming infinite total variation on every interval.\n",
    "4. **Self-similarity:** $B(ct) \\stackrel{d}{=} \\sqrt{c}\\,B(t)$ -- zooming in reveals statistically identical structure at every scale.\n",
    "5. **Reflection principle:** $P(\\max_{s \\leq t} B_s \\geq a) = 2P(B_t \\geq a)$, leading to the Levy distribution for hitting times.\n",
    "6. These properties make Brownian motion a natural model for financial log-returns and the foundation of Ito calculus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}